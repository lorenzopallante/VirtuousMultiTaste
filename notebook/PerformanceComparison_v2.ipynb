{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "For the present notebook you should use two separate conda envs to run Virtuous models and the BitterSweet one \n",
    "\n",
    "- VIRTUOUS \n",
    "- BITTERSWEET2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "notebook_path = os.path.realpath(os.getcwd())\n",
    "root_dir_path = os.path.dirname(notebook_path)\n",
    "code_path = root_dir_path + os.sep + \"VirtuousMultiTaste\" + os.sep\n",
    "src_path = code_path + os.sep + \"src\" + os.sep\n",
    "data_path = root_dir_path + os.sep + \"data\" + os.sep\n",
    "test_path = os.path.join(notebook_path, 'test')\n",
    "\n",
    "# bittersweet path -> path where the bittersweet model is stored\n",
    "bittersweet_path = '/home/lorenzo/Scaricati/bittersweet/'\n",
    "\n",
    "# File used for performance comparison (compounds not in the test set of VirtuousMultiTaste and VirtuousBitterSweet)\n",
    "test_file = data_path + 'PerformanceComparison' + os.sep + 'Bitter_sweet_external_dataset_v2.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare datasets for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test set\n",
    "df_test = pd.read_csv(test_file, sep=',')\n",
    "# create text files for bittersweet\n",
    "df_test[[\"Taste\", \"Parent_SMILES\"]].to_csv(data_path + 'PerformanceComparison' + os.sep + 'test_for_bittersweet_v2.csv', sep=',', index=False, header=False)\n",
    "# create text files for VirtuousMultiTaste and VirtuousBitterSweet\n",
    "df_test[\"Parent_SMILES\"].to_csv(data_path + 'PerformanceComparison' + os.sep + 'test_for_Virtuous_v2.csv', sep=',', index=False, header=False)\n",
    "df_test[\"Taste\"].to_csv(data_path + 'PerformanceComparison' + os.sep + 'test_for_Virtuous_labels_v2.csv', sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sweet     460\n",
       "Bitter    409\n",
       "Name: Taste, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.Taste.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BitterSweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.19.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.19.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdir = data_path + '/PerformanceComparison/bittersweet_v2'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "os.chdir(bittersweet_path)\n",
    "\n",
    "#subprocess.call(['python', bittersweet_path +  'predict.py', data_path + 'test_for_bittersweet_v2.csv' , 'smiles', outdir])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VirtuousMultiTaste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to VirtuousMultiTaste env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1111::2929::5959] ] Initializing Normalizer\n",
      "Initializing Normalizer\n",
      "[11:29:59] Initializing Normalizer\n",
      "[11:29:59] Initializing Normalizer\n",
      "[11:29:59] Initializing Normalizer\n",
      "[11:29:59] Initializing Normalizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/lorenzo/Documenti/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/testing_fourtaste.py:1171: RuntimeWarning: invalid value encountered in greater\n",
      "  df.values[df.values > 1.9399999999999998e+33] = 1.9399999999999998e+33\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.1 when using version 0.22.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "ERROR:root:PID:0\tJOB:0\tUSER:unknown\tAn error occurred during the prediction step.\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/lorenzo/Documenti/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/testing_fourtaste.py\", line 500, in predict_fun_thread\n",
      "    p2 = clf.predict_proba(new_x)  # X is single sample\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 656, in predict_proba\n",
      "    X = self._validate_X_predict(X)\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 412, in _validate_X_predict\n",
      "    return self.estimators_[0]._validate_X_predict(X, check_input=True)\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 387, in _validate_X_predict\n",
      "    if self.n_features_ != n_features:\n",
      "AttributeError: 'DecisionTreeClassifier' object has no attribute 'n_features_'\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lorenzo/Documenti/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/testing_fourtaste.py\", line 624, in predictor\n",
      "    predicted_class = prediction.predict_fun_parallel()\n",
      "  File \"/home/lorenzo/Documenti/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/testing_fourtaste.py\", line 426, in predict_fun_parallel\n",
      "    Parallel(n_jobs=14, verbose=0)(delayed(self.predict_fun_thread)(patient)\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/parallel.py\", line 1056, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/parallel.py\", line 935, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
      "    return self.__get_result()\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
      "    raise self._exception\n",
      "AttributeError: 'DecisionTreeClassifier' object has no attribute 'n_features_'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lorenzo/Documenti/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/VirtuousMultiTaste.py\", line 208, in <module>\n",
      "    ret     = testing_fourtaste.run_all(dataset, maximums_filename1, minimums_filename1,\n",
      "  File \"/home/lorenzo/Documenti/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/testing_fourtaste.py\", line 271, in run_all\n",
      "    result = select_predictor(testset, features, model_filename, training_labels_filename,\n",
      "  File \"/home/lorenzo/Documenti/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/testing_fourtaste.py\", line 67, in select_predictor\n",
      "    index = np.where(i == np.amax(i))\n",
      "  File \"<__array_function__ internals>\", line 5, in amax\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 2754, in amax\n",
      "    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "  File \"/home/lorenzo/anaconda3/envs/VIRTUOUS/lib/python3.8/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "TypeError: cannot perform reduce with flexible type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(root_dir_path)\n",
    "\n",
    "outdir = data_path + '/PerformanceComparison/VirtuousMultiTaste_v2'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# run '''python VirtuousMultiTaste/VirtuousMultiTaste.py -f data/PerformanceComparison/test_for_Virtuous_v2.csv -t 'SMILES' -d data/PerformanceComparison/VirtuousMultiTaste_v2/'''\n",
    "#subprocess.call(['python', code_path + 'VirtuousMultiTaste.py', '-f', data_path + 'PerformanceComparison/test_for_Virtuous.csv', '-t', 'SMILES', '-d', 'data/PerformanceComparison/VirtuousMultiTaste/'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VirtuousSweetBitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file '/Users/lorenzo/Documents/GitHub/VirtuousMultiTaste/VirtuousMultiTaste/../VirtuousSweetBitter/scripts/VirtuousSweetBitter.py': [Errno 2] No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(root_dir_path)\n",
    "\n",
    "outdir = data_path + '/PerformanceComparison/VirtuousSweetBitter_v2'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# run '''python VirtuousMultiTaste/VirtuousMultiTaste.py -f data/PerformanceComparison/test_for_Virtuous.csv -t 'SMILES' -d data/PerformanceComparison/VirtuousMultiTaste/'''\n",
    "#subprocess.call(['python', code_path + '../VirtuousSweetBitter/scripts/VirtuousSweetBitter.py', '-f', data_path + 'PerformanceComparison/test_for_Virtuous_v2.csv', '-t', 'SMILES', '-d', 'data/PerformanceComparison/VirtuousSweetBitter_v2/'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results from BitterSweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Real Predicted\n",
       "0   Sweet     Other\n",
       "1  Bitter    Bitter\n",
       "2  Bitter    Bitter\n",
       "3   Sweet    Bitter\n",
       "4  Bitter    Bitter"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analysed the predictions\n",
    "bitter_sweet_pred = pd.read_csv(data_path + '/PerformanceComparison/bittersweet_v2/output.csv', sep=',')\n",
    "bitter_sweet_pred[[\"name\", \"bitter_taste\", \"bitter_prob\", \"sweet_taste\", \"sweet_prob\"]].head()\n",
    "# if sweet_taste is True, then the compound is predicted as sweet\n",
    "# if bitter_taste is True, then the compound is predicted as bitter\n",
    "# if both are False, then the compound is predicted as other\n",
    "bitter_sweet_pred[\"Predicted_Taste\"] = np.where(bitter_sweet_pred[\"bitter_taste\"] == True, \"Bitter\", np.where(bitter_sweet_pred[\"sweet_taste\"] == True, \"Sweet\", \"Other\"))\n",
    "# rename column name\n",
    "bitter_sweet_pred[[\"name\", \"bitter_taste\", \"bitter_prob\", \"sweet_taste\", \"sweet_prob\", \"Predicted_Taste\"]].head()\n",
    "\n",
    "BitterSweet_df = pd.DataFrame()\n",
    "BitterSweet_df[\"Real\"] = bitter_sweet_pred[\"name\"]\n",
    "BitterSweet_df[\"Predicted\"] = bitter_sweet_pred[\"Predicted_Taste\"]\n",
    "BitterSweet_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results from VirtuousMultiTaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Real Predicted\n",
       "0   Sweet    Bitter\n",
       "1  Bitter     Other\n",
       "2  Bitter    Bitter\n",
       "3   Sweet     Sweet\n",
       "4  Bitter    Bitter"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VirtuousMultiTaste_pred = pd.read_csv(data_path + '/PerformanceComparison/VirtuousMultiTaste_v2/result_dominant_label.txt', sep='\\t', header=None)\n",
    "# name columns\n",
    "VirtuousMultiTaste_pred.columns = [\"Predicted_Taste\", \"Probability\"]\n",
    "# Umami will be converted to Other\n",
    "VirtuousMultiTaste_pred[\"Predicted_Taste\"] = np.where(VirtuousMultiTaste_pred[\"Predicted_Taste\"] == \"Umami\", \"Other\", VirtuousMultiTaste_pred[\"Predicted_Taste\"])\n",
    "# ordering stuff\n",
    "VirtuousMultiTaste_df = pd.DataFrame()\n",
    "VirtuousMultiTaste_df[\"Real\"] = df_test[\"Taste\"]\n",
    "VirtuousMultiTaste_df[\"Predicted\"] = VirtuousMultiTaste_pred[\"Predicted_Taste\"]\n",
    "VirtuousMultiTaste_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load results from VirtuousSweetBitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>Sweet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>Bitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Real Predicted\n",
       "0   Sweet     Sweet\n",
       "1  Bitter     Sweet\n",
       "2  Bitter    Bitter\n",
       "3   Sweet     Sweet\n",
       "4  Bitter    Bitter"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VirtuousSweetBitter_pred = pd.read_csv(data_path + '/PerformanceComparison/VirtuousSweetBitter_v2/predictions.csv', sep=',')\n",
    "# if check_AD is False, then the predicted taste is Other\n",
    "# if check_AD is True, then the predicted taste the predcited taste\n",
    "VirtuousSweetBitter_pred[\"Class\"] = np.where(VirtuousSweetBitter_pred[\"Check AD\"] == False, \"Other\", VirtuousSweetBitter_pred[\"Class\"])\n",
    "\n",
    "# # ordering stuff\n",
    "VirtuousSweetBitter_df = pd.DataFrame()\n",
    "VirtuousSweetBitter_df[\"Real\"] = df_test[\"Taste\"]\n",
    "VirtuousSweetBitter_df[\"Predicted\"] = VirtuousSweetBitter_pred[\"Class\"]\n",
    "VirtuousSweetBitter_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numnber of compounds in the test set: 869\n",
      "Number of compounds from bittersweet: 868\n",
      "Number of compounds from VirtuousMultiTaste: 869\n",
      "Number of compounds from VirtuousSweetBitter: 869\n"
     ]
    }
   ],
   "source": [
    "print (\"Numnber of compounds in the test set: {}\".format(len(df_test)))\n",
    "print (\"Number of compounds from bittersweet: {}\".format(len(bitter_sweet_pred)))\n",
    "print (\"Number of compounds from VirtuousMultiTaste: {}\".format(len(VirtuousMultiTaste_pred)))\n",
    "print (\"Number of compounds from VirtuousSweetBitter: {}\".format(len(VirtuousSweetBitter_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Directly Calculate accuracy and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzo/opt/anaconda3/envs/VIRTUOUS/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lorenzo/opt/anaconda3/envs/VIRTUOUS/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lorenzo/opt/anaconda3/envs/VIRTUOUS/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BitterSweet</td>\n",
       "      <td>62.10</td>\n",
       "      <td>51.95</td>\n",
       "      <td>41.60</td>\n",
       "      <td>46.05</td>\n",
       "      <td>43.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirtuousSweetBitter</td>\n",
       "      <td>78.83</td>\n",
       "      <td>54.01</td>\n",
       "      <td>52.91</td>\n",
       "      <td>52.91</td>\n",
       "      <td>52.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VirtuousMultiTaste</td>\n",
       "      <td>63.18</td>\n",
       "      <td>55.73</td>\n",
       "      <td>42.36</td>\n",
       "      <td>47.95</td>\n",
       "      <td>44.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Set  Accuracy  Precision  Recall     F1     F2\n",
       "0          BitterSweet     62.10      51.95   41.60  46.05  43.25\n",
       "1  VirtuousSweetBitter     78.83      54.01   52.91  52.91  52.78\n",
       "2   VirtuousMultiTaste     63.18      55.73   42.36  47.95  44.40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate performance\n",
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score, precision_score, recall_score\n",
    "\n",
    "test_performance = pd.DataFrame()\n",
    "test_performance ['Set'] = ['BitterSweet', 'VirtuousSweetBitter', 'VirtuousMultiTaste']\n",
    "test_performance ['Accuracy'] = [accuracy_score(BitterSweet_df[\"Real\"], BitterSweet_df[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousSweetBitter_df[\"Real\"], VirtuousSweetBitter_df[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousMultiTaste_df[\"Real\"], VirtuousMultiTaste_df[\"Predicted\"]).round(4)*100]\n",
    "test_performance ['Precision'] = [precision_score(BitterSweet_df[\"Real\"], BitterSweet_df[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousSweetBitter_df[\"Real\"], VirtuousSweetBitter_df[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousMultiTaste_df[\"Real\"], VirtuousMultiTaste_df[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance ['Recall'] = [recall_score(BitterSweet_df[\"Real\"], BitterSweet_df[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousSweetBitter_df[\"Real\"], VirtuousSweetBitter_df[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousMultiTaste_df[\"Real\"], VirtuousMultiTaste_df[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance ['F1'] = [f1_score(BitterSweet_df[\"Real\"], BitterSweet_df[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousSweetBitter_df[\"Real\"], VirtuousSweetBitter_df[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousMultiTaste_df[\"Real\"], VirtuousMultiTaste_df[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance ['F2'] = [fbeta_score(BitterSweet_df[\"Real\"], BitterSweet_df[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousSweetBitter_df[\"Real\"], VirtuousSweetBitter_df[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousMultiTaste_df[\"Real\"], VirtuousMultiTaste_df[\"Predicted\"], average='macro', beta=2).round(4)*100]\n",
    "test_performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Trying with not considering compounds predicted as Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BitterSweet_df2 = BitterSweet_df.copy()\n",
    "BitterSweet_df2 = BitterSweet_df2[BitterSweet_df2[\"Predicted\"] != 'Other']\n",
    "\n",
    "VirtuousMultiTaste_df2 = VirtuousMultiTaste_df.copy()\n",
    "VirtuousMultiTaste_df2 = VirtuousMultiTaste_df2[VirtuousMultiTaste_df2[\"Predicted\"] != 'Other']\n",
    "\n",
    "VirtuousSweetBitter_df2 = VirtuousSweetBitter_df.copy()\n",
    "VirtuousSweetBitter_df2 = VirtuousSweetBitter_df2[VirtuousSweetBitter_df2[\"Predicted\"] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BitterSweet</td>\n",
       "      <td>77.78</td>\n",
       "      <td>77.92</td>\n",
       "      <td>77.83</td>\n",
       "      <td>77.77</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirtuousSweetBitter</td>\n",
       "      <td>80.02</td>\n",
       "      <td>81.02</td>\n",
       "      <td>80.47</td>\n",
       "      <td>79.98</td>\n",
       "      <td>80.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VirtuousMultiTaste</td>\n",
       "      <td>83.43</td>\n",
       "      <td>83.60</td>\n",
       "      <td>83.45</td>\n",
       "      <td>83.42</td>\n",
       "      <td>83.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Set  Accuracy  Precision  Recall     F1     F2\n",
       "0          BitterSweet     77.78      77.92   77.83  77.77  77.78\n",
       "1  VirtuousSweetBitter     80.02      81.02   80.47  79.98  80.09\n",
       "2   VirtuousMultiTaste     83.43      83.60   83.45  83.42  83.41"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance_2 = pd.DataFrame()\n",
    "test_performance_2 ['Set'] = ['BitterSweet', 'VirtuousSweetBitter', 'VirtuousMultiTaste']\n",
    "test_performance_2 ['Accuracy'] = [accuracy_score(BitterSweet_df2[\"Real\"], BitterSweet_df2[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousSweetBitter_df2[\"Real\"], VirtuousSweetBitter_df2[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousMultiTaste_df2[\"Real\"], VirtuousMultiTaste_df2[\"Predicted\"]).round(4)*100]\n",
    "test_performance_2 ['Precision'] = [precision_score(BitterSweet_df2[\"Real\"], BitterSweet_df2[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousSweetBitter_df2[\"Real\"], VirtuousSweetBitter_df2[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousMultiTaste_df2[\"Real\"], VirtuousMultiTaste_df2[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_2 ['Recall'] = [recall_score(BitterSweet_df2[\"Real\"], BitterSweet_df2[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousSweetBitter_df2[\"Real\"], VirtuousSweetBitter_df2[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousMultiTaste_df2[\"Real\"], VirtuousMultiTaste_df2[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_2 ['F1'] = [f1_score(BitterSweet_df2[\"Real\"], BitterSweet_df2[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousSweetBitter_df2[\"Real\"], VirtuousSweetBitter_df2[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousMultiTaste_df2[\"Real\"], VirtuousMultiTaste_df2[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_2 ['F2'] = [fbeta_score(BitterSweet_df2[\"Real\"], BitterSweet_df2[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousSweetBitter_df2[\"Real\"], VirtuousSweetBitter_df2[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousMultiTaste_df2[\"Real\"], VirtuousMultiTaste_df2[\"Predicted\"], average='macro', beta=2).round(4)*100]\n",
    "test_performance_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of compounds in the test set: 869\n",
      "-------------------------------------\n",
      "Number of compounds from BitterSweet: 868\n",
      "Number of compounds from VirtuousSweetBitter: 869\n",
      "Number of compounds from VirtuousMultiTaste: 869\n",
      "-------------------------------------\n",
      "Number of compounds from BitterSweet (Removing Other): 693\n",
      "Number of compounds from VirtuousSweetBitter (Removing Other): 856\n",
      "Number of compounds from VirtuousMultiTaste (Removing Other): 658\n"
     ]
    }
   ],
   "source": [
    "# prinnt number of compuounds in each set\n",
    "print(\"Number of compounds in the test set: \" + str(len(df_test)))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Number of compounds from BitterSweet: \" + str(len(BitterSweet_df)))\n",
    "print(\"Number of compounds from VirtuousSweetBitter: \" + str(len(VirtuousSweetBitter_df)))\n",
    "print(\"Number of compounds from VirtuousMultiTaste: \" + str(len(VirtuousMultiTaste_df)))\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Number of compounds from BitterSweet (Removing Other): \" + str(len(BitterSweet_df2)))\n",
    "print(\"Number of compounds from VirtuousSweetBitter (Removing Other): \" + str(len(VirtuousSweetBitter_df2)))\n",
    "print(\"Number of compounds from VirtuousMultiTaste (Removing Other): \" + str(len(VirtuousMultiTaste_df2)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Calculate only the ability to predict Sweet and Bitter compounds alone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweet accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the database for sweet and bitter\n",
    "BitterSweet_df3 = pd.DataFrame()\n",
    "BitterSweet_df3[\"Real\"] = np.where(BitterSweet_df[\"Real\"] == \"Bitter\", \"non-Sweet\", \"Sweet\")\n",
    "BitterSweet_df3[\"Predicted\"] = np.where(BitterSweet_df[\"Predicted\"] == \"Bitter\", \"non-Sweet\", np.where(BitterSweet_df[\"Predicted\"] == \"Other\", \"non-Sweet\", \"Sweet\"))\n",
    "\n",
    "VirtuousMultiTaste_df3 = pd.DataFrame()\n",
    "VirtuousMultiTaste_df3[\"Real\"] = np.where(VirtuousMultiTaste_df[\"Real\"] == \"Bitter\", \"non-Sweet\", \"Sweet\")\n",
    "VirtuousMultiTaste_df3[\"Predicted\"] = np.where(VirtuousMultiTaste_df[\"Predicted\"] == \"Bitter\", \"non-Sweet\", np.where(VirtuousMultiTaste_df[\"Predicted\"] == \"Other\", \"non-Sweet\", \"Sweet\"))\n",
    "\n",
    "VirtuousSweetBitter_df3 = pd.DataFrame()\n",
    "VirtuousSweetBitter_df3[\"Real\"] = np.where(VirtuousSweetBitter_df[\"Real\"] == \"Bitter\", \"non-Sweet\", \"Sweet\")\n",
    "VirtuousSweetBitter_df3[\"Predicted\"] = np.where(VirtuousSweetBitter_df[\"Predicted\"] == \"Bitter\", \"non-Sweet\", np.where(VirtuousSweetBitter_df[\"Predicted\"] == \"Other\", \"non-Sweet\", \"Sweet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BitterSweet (Sweet)</td>\n",
       "      <td>69.93</td>\n",
       "      <td>72.01</td>\n",
       "      <td>70.72</td>\n",
       "      <td>69.65</td>\n",
       "      <td>69.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirtuousSweetBitter (Sweet)</td>\n",
       "      <td>79.17</td>\n",
       "      <td>80.36</td>\n",
       "      <td>79.73</td>\n",
       "      <td>79.12</td>\n",
       "      <td>79.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VirtuousMultiTaste (Sweet)</td>\n",
       "      <td>72.50</td>\n",
       "      <td>75.56</td>\n",
       "      <td>73.44</td>\n",
       "      <td>72.11</td>\n",
       "      <td>72.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Set  Accuracy  Precision  Recall     F1     F2\n",
       "0          BitterSweet (Sweet)     69.93      72.01   70.72  69.65  69.90\n",
       "1  VirtuousSweetBitter (Sweet)     79.17      80.36   79.73  79.12  79.27\n",
       "2   VirtuousMultiTaste (Sweet)     72.50      75.56   73.44  72.11  72.37"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate perfroamnce for sweet\n",
    "test_performance_3 = pd.DataFrame()\n",
    "test_performance_3 ['Set'] = ['BitterSweet (Sweet)', 'VirtuousSweetBitter (Sweet)', 'VirtuousMultiTaste (Sweet)']\n",
    "test_performance_3 ['Accuracy'] = [accuracy_score(BitterSweet_df3[\"Real\"], BitterSweet_df3[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousSweetBitter_df3[\"Real\"], VirtuousSweetBitter_df3[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousMultiTaste_df3[\"Real\"], VirtuousMultiTaste_df3[\"Predicted\"]).round(4)*100]\n",
    "test_performance_3 ['Precision'] = [precision_score(BitterSweet_df3[\"Real\"], BitterSweet_df3[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousSweetBitter_df3[\"Real\"], VirtuousSweetBitter_df3[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousMultiTaste_df3[\"Real\"], VirtuousMultiTaste_df3[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_3 ['Recall'] = [recall_score(BitterSweet_df3[\"Real\"], BitterSweet_df3[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousSweetBitter_df3[\"Real\"], VirtuousSweetBitter_df3[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousMultiTaste_df3[\"Real\"], VirtuousMultiTaste_df3[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_3 ['F1'] = [f1_score(BitterSweet_df3[\"Real\"], BitterSweet_df3[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousSweetBitter_df3[\"Real\"], VirtuousSweetBitter_df3[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousMultiTaste_df3[\"Real\"], VirtuousMultiTaste_df3[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_3 ['F2'] = [fbeta_score(BitterSweet_df3[\"Real\"], BitterSweet_df3[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousSweetBitter_df3[\"Real\"], VirtuousSweetBitter_df3[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousMultiTaste_df3[\"Real\"], VirtuousMultiTaste_df3[\"Predicted\"], average='macro', beta=2).round(4)*100]\n",
    "test_performance_3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitter accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize the database for sweet and bitter\n",
    "BitterSweet_df4 = pd.DataFrame()\n",
    "BitterSweet_df4[\"Real\"] = np.where(BitterSweet_df2[\"Real\"] == \"Sweet\", \"non-Bitter\", \"Bitter\")\n",
    "BitterSweet_df4[\"Predicted\"] = np.where(BitterSweet_df2[\"Predicted\"] == \"Sweet\", \"non-Bitter\", np.where(BitterSweet_df2[\"Predicted\"] == \"Other\", \"non-Bitter\", \"Bitter\"))\n",
    "\n",
    "VirtuousMultiTaste_df4 = pd.DataFrame()\n",
    "VirtuousMultiTaste_df4[\"Real\"] = np.where(VirtuousMultiTaste_df2[\"Real\"] == \"Sweet\", \"non-Bitter\", \"Bitter\")\n",
    "VirtuousMultiTaste_df4[\"Predicted\"] = np.where(VirtuousMultiTaste_df2[\"Predicted\"] == \"Sweet\", \"non-Bitter\", np.where(VirtuousMultiTaste_df2[\"Predicted\"] == \"Other\", \"non-Bitter\", \"Bitter\"))\n",
    "\n",
    "VirtuousSweetBitter_df4 = pd.DataFrame()\n",
    "VirtuousSweetBitter_df4[\"Real\"] = np.where(VirtuousSweetBitter_df2[\"Real\"] == \"Sweet\", \"non-Bitter\", \"Bitter\")\n",
    "VirtuousSweetBitter_df4[\"Predicted\"] = np.where(VirtuousSweetBitter_df2[\"Predicted\"] == \"Sweet\", \"non-Bitter\", np.where(VirtuousSweetBitter_df2[\"Predicted\"] == \"Other\", \"non-Bitter\", \"Bitter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BitterSweet (Bitter)</td>\n",
       "      <td>77.78</td>\n",
       "      <td>77.92</td>\n",
       "      <td>77.83</td>\n",
       "      <td>77.77</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirtuousSweetBitter (Bitter)</td>\n",
       "      <td>80.02</td>\n",
       "      <td>81.02</td>\n",
       "      <td>80.47</td>\n",
       "      <td>79.98</td>\n",
       "      <td>80.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VirtuousMultiTaste (Bitter)</td>\n",
       "      <td>83.43</td>\n",
       "      <td>83.60</td>\n",
       "      <td>83.45</td>\n",
       "      <td>83.42</td>\n",
       "      <td>83.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Set  Accuracy  Precision  Recall     F1     F2\n",
       "0          BitterSweet (Bitter)     77.78      77.92   77.83  77.77  77.78\n",
       "1  VirtuousSweetBitter (Bitter)     80.02      81.02   80.47  79.98  80.09\n",
       "2   VirtuousMultiTaste (Bitter)     83.43      83.60   83.45  83.42  83.41"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate perfroamnce for bitter \n",
    "test_performance_4 = pd.DataFrame()\n",
    "test_performance_4 ['Set'] = ['BitterSweet (Bitter)', 'VirtuousSweetBitter (Bitter)', 'VirtuousMultiTaste (Bitter)']\n",
    "test_performance_4 ['Accuracy'] = [accuracy_score(BitterSweet_df4[\"Real\"], BitterSweet_df4[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousSweetBitter_df4[\"Real\"], VirtuousSweetBitter_df4[\"Predicted\"]).round(4)*100, accuracy_score(VirtuousMultiTaste_df4[\"Real\"], VirtuousMultiTaste_df4[\"Predicted\"]).round(4)*100]\n",
    "test_performance_4 ['Precision'] = [precision_score(BitterSweet_df4[\"Real\"], BitterSweet_df4[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousSweetBitter_df4[\"Real\"], VirtuousSweetBitter_df4[\"Predicted\"], average='macro').round(4)*100, precision_score(VirtuousMultiTaste_df4[\"Real\"], VirtuousMultiTaste_df4[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_4 ['Recall'] = [recall_score(BitterSweet_df4[\"Real\"], BitterSweet_df4[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousSweetBitter_df4[\"Real\"], VirtuousSweetBitter_df4[\"Predicted\"], average='macro').round(4)*100, recall_score(VirtuousMultiTaste_df4[\"Real\"], VirtuousMultiTaste_df4[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_4 ['F1'] = [f1_score(BitterSweet_df4[\"Real\"], BitterSweet_df4[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousSweetBitter_df4[\"Real\"], VirtuousSweetBitter_df4[\"Predicted\"], average='macro').round(4)*100, f1_score(VirtuousMultiTaste_df4[\"Real\"], VirtuousMultiTaste_df4[\"Predicted\"], average='macro').round(4)*100]\n",
    "test_performance_4 ['F2'] = [fbeta_score(BitterSweet_df4[\"Real\"], BitterSweet_df4[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousSweetBitter_df4[\"Real\"], VirtuousSweetBitter_df4[\"Predicted\"], average='macro', beta=2).round(4)*100, fbeta_score(VirtuousMultiTaste_df4[\"Real\"], VirtuousMultiTaste_df4[\"Predicted\"], average='macro', beta=2).round(4)*100]\n",
    "test_performance_4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bittersweet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
